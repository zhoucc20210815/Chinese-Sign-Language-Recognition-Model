{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Mediapipe gesture recognizer (This file runs on Colab)"]},{"cell_type":"markdown","metadata":{},"source":["The code in this notebook is sourced from the official MediaPipe documentation. I made minor adjustments to adapt it for my custom dataset. The source code link is: [Hand gesture recognition model customization guide](https://colab.research.google.com/github/googlesamples/mediapipe/blob/main/examples/customization/gesture_recognizer.ipynb#scrollTo=f1UMEG85hQL_)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31060,"status":"ok","timestamp":1709841674608,"user":{"displayName":"zixi Zhou","userId":"12809078263263410263"},"user_tz":0},"id":"FU06E0IfE29Y","outputId":"09f5c55b-c960-483a-b4cb-8234a89f7700"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n","Collecting pip\n","  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 23.1.2\n","    Uninstalling pip-23.1.2:\n","      Successfully uninstalled pip-23.1.2\n","Successfully installed pip-24.0\n","Collecting mediapipe-model-maker\n","  Downloading mediapipe_model_maker-0.2.1.3-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (1.4.0)\n","Collecting mediapipe>=0.10.0 (from mediapipe-model-maker)\n","  Downloading mediapipe-0.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (1.25.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (4.8.0.76)\n","Requirement already satisfied: tensorflow>=2.10 in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (2.15.0)\n","Collecting tensorflow-addons (from mediapipe-model-maker)\n","  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (4.9.4)\n","Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (0.16.1)\n","Collecting tf-models-official>=2.13.1 (from mediapipe-model-maker)\n","  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (23.2.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (23.5.26)\n","Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.4.23)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.4.23+cuda12.cudnn89)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (3.7.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (2.1.0+cu121)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (4.8.0.76)\n","Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (3.20.3)\n","Collecting sounddevice>=0.4.4 (from mediapipe>=0.10.0->mediapipe-model-maker)\n","  Downloading sounddevice-0.4.6-py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (1.6.3)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (23.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (4.10.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (0.36.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (1.62.0)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (2.15.0)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (3.0.9)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (9.4.0)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (0.5.0)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (2.84.0)\n","Collecting immutabledict (from tf-models-official>=2.13.1->mediapipe-model-maker)\n","  Downloading immutabledict-4.2.0-py3-none-any.whl.metadata (3.4 kB)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (1.5.16)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (4.1.3)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (4.9.0.80)\n","Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (1.5.3)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (5.9.5)\n","Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (9.0.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (2.0.7)\n","Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (6.0.1)\n","Collecting sacrebleu (from tf-models-official>=2.13.1->mediapipe-model-maker)\n","  Downloading sacrebleu-2.4.0-py3-none-any.whl.metadata (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (1.11.4)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (0.1.99)\n","Collecting seqeval (from tf-models-official>=2.13.1->mediapipe-model-maker)\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.13.1->mediapipe-model-maker)\n","  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n","Collecting tensorflow-text~=2.15.0 (from tf-models-official>=2.13.1->mediapipe-model-maker)\n","  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n","Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (1.1.0)\n","Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub->mediapipe-model-maker) (2.15.0)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->mediapipe-model-maker)\n","  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (8.1.7)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.1.8)\n","Requirement already satisfied: etils>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->mediapipe-model-maker) (1.7.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.31.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (1.14.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.10.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (4.66.2)\n","Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.5.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.10->mediapipe-model-maker) (0.42.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->mediapipe-model-maker) (2023.6.0)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->mediapipe-model-maker) (6.1.2)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->mediapipe-model-maker) (3.17.0)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.13.1->mediapipe-model-maker) (0.22.0)\n","Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.13.1->mediapipe-model-maker) (2.27.0)\n","Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.13.1->mediapipe-model-maker) (0.1.1)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.13.1->mediapipe-model-maker) (2.11.1)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.13.1->mediapipe-model-maker) (4.1.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (2024.2.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (2.8.2)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (8.0.4)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (2.0.7)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (6.1.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->tf-models-official>=2.13.1->mediapipe-model-maker) (2023.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->mediapipe-model-maker) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->mediapipe-model-maker) (3.6)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (1.16.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (3.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (3.0.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (4.49.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (3.1.1)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.13.1->mediapipe-model-maker) (0.5.1)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.13.1->mediapipe-model-maker) (0.3.0)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.13.1->mediapipe-model-maker) (4.9)\n","Collecting portalocker (from sacrebleu->tf-models-official>=2.13.1->mediapipe-model-maker)\n","  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official>=2.13.1->mediapipe-model-maker) (2023.12.25)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official>=2.13.1->mediapipe-model-maker) (0.9.0)\n","Collecting colorama (from sacrebleu->tf-models-official>=2.13.1->mediapipe-model-maker)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official>=2.13.1->mediapipe-model-maker) (4.9.4)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official>=2.13.1->mediapipe-model-maker) (1.2.2)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->mediapipe-model-maker) (1.62.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe>=0.10.0->mediapipe-model-maker) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe>=0.10.0->mediapipe-model-maker) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe>=0.10.0->mediapipe-model-maker) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe>=0.10.0->mediapipe-model-maker) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe>=0.10.0->mediapipe-model-maker) (2.1.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (2.21)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.13.1->mediapipe-model-maker) (5.3.3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (1.3.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.13.1->mediapipe-model-maker) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.13.1->mediapipe-model-maker) (3.3.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (2.1.5)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (0.5.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mediapipe>=0.10.0->mediapipe-model-maker) (1.3.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (3.2.2)\n","Downloading mediapipe_model_maker-0.2.1.3-py3-none-any.whl (127 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.0/128.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mediapipe-0.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n","Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Downloading immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\n","Downloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=d911558511937bc816b3b808b55f3c58e02dbb819d6d47c800bce7fcb1dbd5ef\n","  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n","Successfully built seqeval\n","Installing collected packages: typeguard, tensorflow-model-optimization, portalocker, immutabledict, colorama, tensorflow-addons, sounddevice, sacrebleu, seqeval, mediapipe, tensorflow-text, tf-models-official, mediapipe-model-maker\n","Successfully installed colorama-0.4.6 immutabledict-4.2.0 mediapipe-0.10.11 mediapipe-model-maker-0.2.1.3 portalocker-2.8.2 sacrebleu-2.4.0 seqeval-1.2.2 sounddevice-0.4.6 tensorflow-addons-0.23.0 tensorflow-model-optimization-0.8.0 tensorflow-text-2.15.0 tf-models-official-2.15.0 typeguard-2.13.3\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install --upgrade pip\n","!pip install mediapipe-model-maker"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12971,"status":"ok","timestamp":1709841689356,"user":{"displayName":"zixi Zhou","userId":"12809078263263410263"},"user_tz":0},"id":"-Ij4qeCZFWpr","outputId":"cfff4f15-f1b4-403c-dac5-02bb81ff293a"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}],"source":["from google.colab import files\n","import os\n","import tensorflow as tf\n","assert tf.__version__.startswith('2')\n","\n","from mediapipe_model_maker import gesture_recognizer\n","\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":245,"status":"ok","timestamp":1709841691306,"user":{"displayName":"zixi Zhou","userId":"12809078263263410263"},"user_tz":0},"id":"aOn02-s6FZuy"},"outputs":[],"source":["dataset_path = \"./drive/My Drive/my_hand_dataset_mediapipe\""]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":202,"status":"ok","timestamp":1709841692996,"user":{"displayName":"zixi Zhou","userId":"12809078263263410263"},"user_tz":0},"id":"GP7hsxTTFbsu","outputId":"a598e7ff-feff-4a0a-efc8-19a7b265284d"},"outputs":[{"name":"stdout","output_type":"stream","text":["./drive/My Drive/my_hand_dataset\n","['can', 'good', 'arrive', 'thank', 'sorry', 'you', 'give', 'food', 'I']\n"]}],"source":["print(dataset_path)\n","labels = []\n","for i in os.listdir(dataset_path):\n","  if os.path.isdir(os.path.join(dataset_path, i)):\n","    labels.append(i)\n","print(labels)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":36540,"status":"ok","timestamp":1709841745578,"user":{"displayName":"zixi Zhou","userId":"12809078263263410263"},"user_tz":0},"id":"iPio6jzOFgHg"},"outputs":[],"source":["# Number of classes\n","NUM_EXAMPLES = 9\n","\n","for label in labels:\n","  label_dir = os.path.join(dataset_path, label)\n","  example_filenames = os.listdir(label_dir)[:NUM_EXAMPLES]\n","  fig, axs = plt.subplots(1, NUM_EXAMPLES, figsize=(10,2))\n","  for i in range(NUM_EXAMPLES):\n","    axs[i].imshow(plt.imread(os.path.join(label_dir, example_filenames[i])))\n","    axs[i].get_xaxis().set_visible(False)\n","    axs[i].get_yaxis().set_visible(False)\n","  fig.suptitle(f'Showing {NUM_EXAMPLES} examples for {label}')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["In this project, I trained the model using default parameters. \n","\n","**ModelOptions:**\n","- dropout_rate: 0.05\n","- layer_widths: []\n","\n","**HParams:**\n","- learning_rate: 0.001\n","- batch_size: 2\n","- epochs: 10\n","- steps_per_epoch: Automatically calculated based on dataset size and batch size\n","- shuffle: False\n","- lr_decay: 0.99\n","- gamma: 2"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":182389,"status":"ok","timestamp":1709841986470,"user":{"displayName":"zixi Zhou","userId":"12809078263263410263"},"user_tz":0},"id":"LY_KQXa6F56O","outputId":"56bbb97d-92ce-49b8-8020-6610f0c550b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://storage.googleapis.com/mediapipe-assets/palm_detection_full.tflite to /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n","Downloading https://storage.googleapis.com/mediapipe-assets/hand_landmark_full.tflite to /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n","Downloading https://storage.googleapis.com/mediapipe-assets/gesture_embedder.tar.gz to /tmp/model_maker/gesture_recognizer/gesture_embedder\n"]}],"source":["data = gesture_recognizer.Dataset.from_folder(\n","    dirname=dataset_path, \n","    hparams=gesture_recognizer.HandDataPreprocessingParams()\n",")\n","\n","# 80% train data, 10% validation data, 10% test data\n","train_data, rest_data = data.split(0.8)\n","validation_data, test_data = rest_data.split(0.5)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48721,"status":"ok","timestamp":1709842068594,"user":{"displayName":"zixi Zhou","userId":"12809078263263410263"},"user_tz":0},"id":"An8BT4juIa_Q","outputId":"d5f72b93-17c7-4988-fd35-dd86cd274262"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," hand_embedding (InputLayer  [(None, 128)]             0         \n"," )                                                               \n","                                                                 \n"," batch_normalization (Batch  (None, 128)               512       \n"," Normalization)                                                  \n","                                                                 \n"," re_lu (ReLU)                (None, 128)               0         \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," custom_gesture_recognizer_  (None, 11)                1419      \n"," out (Dense)                                                     \n","                                                                 \n","=================================================================\n","Total params: 1931 (7.54 KB)\n","Trainable params: 1675 (6.54 KB)\n","Non-trainable params: 256 (1.00 KB)\n","_________________________________________________________________\n","None\n","Epoch 1/10\n","637/637 [==============================] - 7s 8ms/step - loss: 1.1797 - categorical_accuracy: 0.4545 - val_loss: 0.2380 - val_categorical_accuracy: 0.9182 - lr: 0.0010\n","Epoch 2/10\n","637/637 [==============================] - 3s 5ms/step - loss: 0.7040 - categorical_accuracy: 0.6758 - val_loss: 0.1151 - val_categorical_accuracy: 0.9560 - lr: 9.9000e-04\n","Epoch 3/10\n","637/637 [==============================] - 3s 5ms/step - loss: 0.6003 - categorical_accuracy: 0.7284 - val_loss: 0.0793 - val_categorical_accuracy: 0.9686 - lr: 9.8010e-04\n","Epoch 4/10\n","637/637 [==============================] - 4s 6ms/step - loss: 0.5474 - categorical_accuracy: 0.7559 - val_loss: 0.0636 - val_categorical_accuracy: 0.9748 - lr: 9.7030e-04\n","Epoch 5/10\n","637/637 [==============================] - 3s 4ms/step - loss: 0.5255 - categorical_accuracy: 0.7771 - val_loss: 0.0551 - val_categorical_accuracy: 0.9811 - lr: 9.6060e-04\n","Epoch 6/10\n","637/637 [==============================] - 3s 5ms/step - loss: 0.5003 - categorical_accuracy: 0.7779 - val_loss: 0.0499 - val_categorical_accuracy: 0.9811 - lr: 9.5099e-04\n","Epoch 7/10\n","637/637 [==============================] - 3s 4ms/step - loss: 0.4772 - categorical_accuracy: 0.7943 - val_loss: 0.0475 - val_categorical_accuracy: 0.9811 - lr: 9.4148e-04\n","Epoch 8/10\n","637/637 [==============================] - 3s 4ms/step - loss: 0.4643 - categorical_accuracy: 0.8038 - val_loss: 0.0441 - val_categorical_accuracy: 0.9811 - lr: 9.3207e-04\n","Epoch 9/10\n","637/637 [==============================] - 3s 5ms/step - loss: 0.4752 - categorical_accuracy: 0.7928 - val_loss: 0.0448 - val_categorical_accuracy: 0.9811 - lr: 9.2274e-04\n","Epoch 10/10\n","637/637 [==============================] - 4s 6ms/step - loss: 0.4550 - categorical_accuracy: 0.8077 - val_loss: 0.0417 - val_categorical_accuracy: 0.9811 - lr: 9.1352e-04\n"]}],"source":["# export_dir: Location of model checkpoint files and exported model files.\n","hparams = gesture_recognizer.HParams(export_dir=\"exported_model\")\n","options = gesture_recognizer.GestureRecognizerOptions(hparams=hparams)\n","model = gesture_recognizer.GestureRecognizer.create(\n","    train_data=train_data,\n","    validation_data=validation_data,\n","    options=options\n",")"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1676,"status":"ok","timestamp":1709842071868,"user":{"displayName":"zixi Zhou","userId":"12809078263263410263"},"user_tz":0},"id":"KJjwYUEjIrTa","outputId":"04a20509-4e46-4ed0-9212-da656ff4ec68"},"outputs":[{"name":"stdout","output_type":"stream","text":["160/160 [==============================] - 1s 2ms/step - loss: 0.1005 - categorical_accuracy: 0.9688\n","Test loss:0.10052342712879181, Test accuracy:0.96875\n"]}],"source":["loss, acc = model.evaluate(test_data, batch_size=1)\n","print(f\"Test loss:{loss}, Test accuracy:{acc}\")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1873,"status":"ok","timestamp":1709842077537,"user":{"displayName":"zixi Zhou","userId":"12809078263263410263"},"user_tz":0},"id":"btRC2bM-It2X","outputId":"b22c29a3-c569-4648-f6fe-7331f69327fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://storage.googleapis.com/mediapipe-assets/gesture_embedder.tflite to /tmp/model_maker/gesture_recognizer/gesture_embedder.tflite\n","Using existing files at /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n","Using existing files at /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n","Downloading https://storage.googleapis.com/mediapipe-assets/canned_gesture_classifier.tflite to /tmp/model_maker/gesture_recognizer/canned_gesture_classifier.tflite\n","best_model_weights.data-00000-of-00001\tcheckpoint    gesture_recognizer.task  metadata.json\n","best_model_weights.index\t\tepoch_models  logs\n"]}],"source":["model.export_model()\n","!ls exported_model"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":217,"status":"ok","timestamp":1709842384913,"user":{"displayName":"zixi Zhou","userId":"12809078263263410263"},"user_tz":0},"id":"cWTrd0R-Iz2B","outputId":"ee1db45c-6063-4b17-8a3f-11becf3e2983"},"outputs":[{"data":{"application/javascript":"\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"download(\"download_36ef4665-9c6e-40bc-8f96-32abce3819e6\", \"gesture_recognizer.task\", 8464514)","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["files.download('exported_model/gesture_recognizer.task')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN7gTh6A8RRMwfaS73u5mGV","mount_file_id":"1_YYgQpFEYQkU-0BBKMo0soYfLX1kR5AM","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
